{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_432_TensorFlow_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "s-Tc3ovEyQ9b"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/terrainthesky-hub/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/module2-backpropagation/Lesley_RichLS_DS_432_TensorFlow_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObyHCH8HvHSf",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# *Data Science Unit 4 Sprint 2 Assignment 2*\n",
        "\n",
        "Use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Please build a baseline classification model then run a few experiments with different optimizers and learning rates. \n",
        "\n",
        "*Don't forgot to switch to GPU on Colab!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Tc3ovEyQ9b",
        "colab_type": "text"
      },
      "source": [
        "## Load Your Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkU0pAYCvU8o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8dab45c9-745d-42b9-9e28-498201974a7e"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "data = np.load('./sample_data/quickdraw10.npz')\n",
        "X = data['arr_0']\n",
        "y = data['arr_1']\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 784)\n",
            "(100000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuYLnTOG702Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "306b84bc-d676-401c-e613-003fa4008146"
      },
      "source": [
        "data.files\n",
        "#last % of dataset .2\n",
        "#"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['arr_0', 'arr_1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8qsDqdqvHDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['apple',\n",
        " 'anvil',\n",
        " 'airplane',\n",
        " 'banana',\n",
        " 'The Eiffel Tower',\n",
        " 'The Mona Lisa',\n",
        " 'The Great Wall of China',\n",
        " 'alarm clock',\n",
        " 'ant',\n",
        " 'asparagus']"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owbm1EbxvA5A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "97babc62-56c2-404e-fd7c-3aa040ccd7b4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,5))\n",
        "start = 0\n",
        "\n",
        "for num, name in enumerate(class_names):\n",
        "    plt.subplot(2,5, num+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X[start].reshape(28,28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(name)\n",
        "    start += 10000\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method NpzFile.__del__ of <numpy.lib.npyio.NpzFile object at 0x7f33b5b4aef0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\", line 230, in __del__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\", line 221, in close\n",
            "    if self.zip is not None:\n",
            "AttributeError: 'NpzFile' object has no attribute 'zip'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb70CbLVyK65",
        "colab_type": "text"
      },
      "source": [
        "## Build Your Baseline Model\n",
        "Some Hints:\n",
        "\n",
        "\n",
        "*  Model should have 784 input values (like mnist)\n",
        "*  Use `sparse_categorical_crossentropy` as your loss function.\n",
        "* You need 10 neurons in your last layer for output\n",
        "* You can add as many hidden layers with as many neurons in them as you like. \n",
        "* The default batchsize should be fine for this exercise.\n",
        "* Limit your model epochs to 30 each time you fit.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHWblzsMyNkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "X, y = shuffle(X, y)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItjhWDSE_FfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be3b08a8-03d2-4600-be29-16b2b744ddcc"
      },
      "source": [
        "sgd = SGD(learning_rate=0.01)\n",
        "\n",
        "model = Sequential([\n",
        "                    Dense(5, activation='sigmoid', input_dim=784),\n",
        "                    Dense(5, activation='sigmoid'),\n",
        "                    Dense(5, activation='sigmoid'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "sgd_default = model.fit(X,y, epochs=30, validation_split=.2, shuffle=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 2.2866 - accuracy: 0.1525 - val_loss: 2.2665 - val_accuracy: 0.2499\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 2.2339 - accuracy: 0.2077 - val_loss: 2.1896 - val_accuracy: 0.2375\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 2.1240 - accuracy: 0.2186 - val_loss: 2.0601 - val_accuracy: 0.1978\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 2.0160 - accuracy: 0.2107 - val_loss: 1.9807 - val_accuracy: 0.2008\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.9587 - accuracy: 0.2292 - val_loss: 1.9496 - val_accuracy: 0.2211\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.9598 - accuracy: 0.2612 - val_loss: 1.9506 - val_accuracy: 0.2675\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.9324 - accuracy: 0.2749 - val_loss: 1.9215 - val_accuracy: 0.2860\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.8981 - accuracy: 0.3268 - val_loss: 1.8879 - val_accuracy: 0.3448\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.8757 - accuracy: 0.3247 - val_loss: 1.8677 - val_accuracy: 0.3411\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.8236 - accuracy: 0.3645 - val_loss: 1.7928 - val_accuracy: 0.3814\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.7590 - accuracy: 0.4046 - val_loss: 1.7200 - val_accuracy: 0.4512\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.6863 - accuracy: 0.4126 - val_loss: 1.6664 - val_accuracy: 0.4027\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.6347 - accuracy: 0.4419 - val_loss: 1.6099 - val_accuracy: 0.4618\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.5959 - accuracy: 0.4588 - val_loss: 1.6012 - val_accuracy: 0.4467\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.5689 - accuracy: 0.4480 - val_loss: 1.5594 - val_accuracy: 0.4639\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.5432 - accuracy: 0.4691 - val_loss: 1.5980 - val_accuracy: 0.4475\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.5344 - accuracy: 0.4655 - val_loss: 1.5188 - val_accuracy: 0.4694\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.5525 - accuracy: 0.4638 - val_loss: 1.5570 - val_accuracy: 0.4611\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.5295 - accuracy: 0.4763 - val_loss: 1.5219 - val_accuracy: 0.4728\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.5012 - accuracy: 0.4851 - val_loss: 1.5239 - val_accuracy: 0.4647\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.4950 - accuracy: 0.4889 - val_loss: 1.5970 - val_accuracy: 0.4657\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.5062 - accuracy: 0.4834 - val_loss: 1.4833 - val_accuracy: 0.4943\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.4734 - accuracy: 0.4909 - val_loss: 1.4689 - val_accuracy: 0.4843\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.4759 - accuracy: 0.4968 - val_loss: 1.4654 - val_accuracy: 0.5058\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.4640 - accuracy: 0.4958 - val_loss: 1.4739 - val_accuracy: 0.4742\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.4549 - accuracy: 0.4873 - val_loss: 1.4666 - val_accuracy: 0.4854\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.4536 - accuracy: 0.4889 - val_loss: 1.4546 - val_accuracy: 0.4794\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.4426 - accuracy: 0.4903 - val_loss: 1.4513 - val_accuracy: 0.4951\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.4504 - accuracy: 0.4854 - val_loss: 1.4701 - val_accuracy: 0.4903\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 1.4450 - accuracy: 0.4968 - val_loss: 1.4629 - val_accuracy: 0.4697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3310187630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAhBrcE4yOZe",
        "colab_type": "text"
      },
      "source": [
        "## Change Optimizers\n",
        "Try using the keras `adam` optimizer instead of `sgd` in your model. Visualize the difference in validation loss between the models with different optimizers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIW_spOZ0cxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a9477126-5766-4ef4-ae98-a9290c946f74"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "sgd = SGD(learning_rate=0.01)\n",
        "\n",
        "model = Sequential([\n",
        "                    Dense(5, activation='sigmoid', input_dim=784),\n",
        "                    Dense(5, activation='sigmoid'),\n",
        "                    Dense(5, activation='sigmoid'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "adam_default = model.fit(X,y, epochs=30, validation_split=.2, shuffle=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0763 - accuracy: 0.2830 - val_loss: 1.7759 - val_accuracy: 0.3586\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.6933 - accuracy: 0.3738 - val_loss: 1.6654 - val_accuracy: 0.3713\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.6145 - accuracy: 0.3997 - val_loss: 1.5898 - val_accuracy: 0.4117\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 9s 3ms/step - loss: 1.5721 - accuracy: 0.4255 - val_loss: 1.5657 - val_accuracy: 0.4288\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.5624 - accuracy: 0.4308 - val_loss: 1.5666 - val_accuracy: 0.4062\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.5270 - accuracy: 0.4394 - val_loss: 1.5178 - val_accuracy: 0.4214\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.4921 - accuracy: 0.4584 - val_loss: 1.5375 - val_accuracy: 0.4439\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.4886 - accuracy: 0.4623 - val_loss: 1.4710 - val_accuracy: 0.4552\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.4617 - accuracy: 0.4608 - val_loss: 1.4578 - val_accuracy: 0.4525\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.4656 - accuracy: 0.4518 - val_loss: 1.4694 - val_accuracy: 0.4568\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.4588 - accuracy: 0.4683 - val_loss: 1.4716 - val_accuracy: 0.4773\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.4257 - accuracy: 0.5047 - val_loss: 1.4347 - val_accuracy: 0.4928\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.4024 - accuracy: 0.5135 - val_loss: 1.4107 - val_accuracy: 0.5066\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3922 - accuracy: 0.5131 - val_loss: 1.4195 - val_accuracy: 0.4864\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3761 - accuracy: 0.5208 - val_loss: 1.3862 - val_accuracy: 0.5145\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3778 - accuracy: 0.5129 - val_loss: 1.4472 - val_accuracy: 0.4773\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3783 - accuracy: 0.5066 - val_loss: 1.3600 - val_accuracy: 0.5218\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3649 - accuracy: 0.5243 - val_loss: 1.3540 - val_accuracy: 0.5258\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3509 - accuracy: 0.5254 - val_loss: 1.3611 - val_accuracy: 0.5286\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3459 - accuracy: 0.5331 - val_loss: 1.3410 - val_accuracy: 0.5465\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3393 - accuracy: 0.5277 - val_loss: 1.3435 - val_accuracy: 0.5254\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3264 - accuracy: 0.5356 - val_loss: 1.3264 - val_accuracy: 0.5488\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3347 - accuracy: 0.5303 - val_loss: 1.3734 - val_accuracy: 0.5195\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3410 - accuracy: 0.5328 - val_loss: 1.3471 - val_accuracy: 0.5213\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3221 - accuracy: 0.5406 - val_loss: 1.3580 - val_accuracy: 0.5335\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3320 - accuracy: 0.5483 - val_loss: 1.3283 - val_accuracy: 0.5511\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3253 - accuracy: 0.5449 - val_loss: 1.3617 - val_accuracy: 0.5217\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3100 - accuracy: 0.5523 - val_loss: 1.3228 - val_accuracy: 0.5498\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3034 - accuracy: 0.5560 - val_loss: 1.3135 - val_accuracy: 0.5598\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.2946 - accuracy: 0.5628 - val_loss: 1.3302 - val_accuracy: 0.5606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgZvcEyu0dWb",
        "colab_type": "text"
      },
      "source": [
        "## Optimize Learning Rate\n",
        "Using the optimizer your picked in the previous step, begin tuning the learning rate within that optimizer. Try manually choosing 3-5 learning rate.values. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUQHcjHU1KLf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "879569cf-f527-4d76-8c92-04bfe3e33daf"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model = Sequential([\n",
        "                    Dense(10, activation='sigmoid', input_dim=784),\n",
        "                    Dense(10, activation='sigmoid'),\n",
        "                    Dense(10, activation='sigmoid'),\n",
        "                    Dense(10, activation='sigmoid'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "adam_low = model.fit(X,y, epochs=30, validation_split=.2, shuffle=True)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0627 - accuracy: 0.2107 - val_loss: 1.9035 - val_accuracy: 0.3141\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.7547 - accuracy: 0.3446 - val_loss: 1.6446 - val_accuracy: 0.3869\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.5686 - accuracy: 0.4340 - val_loss: 1.5060 - val_accuracy: 0.4807\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 9s 4ms/step - loss: 1.4373 - accuracy: 0.5035 - val_loss: 1.3803 - val_accuracy: 0.5009\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3594 - accuracy: 0.5190 - val_loss: 1.3563 - val_accuracy: 0.5097\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3390 - accuracy: 0.5320 - val_loss: 1.3385 - val_accuracy: 0.5390\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.2962 - accuracy: 0.5641 - val_loss: 1.2795 - val_accuracy: 0.5695\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.2695 - accuracy: 0.5727 - val_loss: 1.2500 - val_accuracy: 0.5957\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.2454 - accuracy: 0.5864 - val_loss: 1.2605 - val_accuracy: 0.5926\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.2466 - accuracy: 0.5898 - val_loss: 1.2503 - val_accuracy: 0.5713\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.1906 - accuracy: 0.6089 - val_loss: 1.1895 - val_accuracy: 0.6229\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.1733 - accuracy: 0.6230 - val_loss: 1.2071 - val_accuracy: 0.6047\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.1614 - accuracy: 0.6179 - val_loss: 1.1601 - val_accuracy: 0.6202\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.1472 - accuracy: 0.6232 - val_loss: 1.1697 - val_accuracy: 0.6174\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.1390 - accuracy: 0.6346 - val_loss: 1.1330 - val_accuracy: 0.6457\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.1337 - accuracy: 0.6292 - val_loss: 1.1397 - val_accuracy: 0.6284\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.1139 - accuracy: 0.6364 - val_loss: 1.1926 - val_accuracy: 0.6036\n",
            "Epoch 18/30\n",
            "2488/2500 [============================>.] - ETA: 0s - loss: 1.1328 - accuracy: 0.6216"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method NpzFile.__del__ of <numpy.lib.npyio.NpzFile object at 0x7f33b598b198>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\", line 230, in __del__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\", line 221, in close\n",
            "    if self.zip is not None:\n",
            "AttributeError: 'NpzFile' object has no attribute 'zip'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.1325 - accuracy: 0.6216 - val_loss: 1.1128 - val_accuracy: 0.6450\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0917 - accuracy: 0.6475 - val_loss: 1.0904 - val_accuracy: 0.6521\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0981 - accuracy: 0.6421 - val_loss: 1.1069 - val_accuracy: 0.6426\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0827 - accuracy: 0.6530 - val_loss: 1.0867 - val_accuracy: 0.6542\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0728 - accuracy: 0.6539 - val_loss: 1.0731 - val_accuracy: 0.6575\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0766 - accuracy: 0.6582 - val_loss: 1.1044 - val_accuracy: 0.6460\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0879 - accuracy: 0.6475 - val_loss: 1.0815 - val_accuracy: 0.6551\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0597 - accuracy: 0.6645 - val_loss: 1.0712 - val_accuracy: 0.6613\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0515 - accuracy: 0.6679 - val_loss: 1.0537 - val_accuracy: 0.6711\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0583 - accuracy: 0.6618 - val_loss: 1.0496 - val_accuracy: 0.6686\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0329 - accuracy: 0.6751 - val_loss: 1.0631 - val_accuracy: 0.6680\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0423 - accuracy: 0.6724 - val_loss: 1.0490 - val_accuracy: 0.6607\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0416 - accuracy: 0.6666 - val_loss: 1.0493 - val_accuracy: 0.6654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LED5NIVEDzJO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a02958ed-5802-4293-8997-c3b07e350ab1"
      },
      "source": [
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.02)\n",
        "\n",
        "model = Sequential([\n",
        "                    Dense(5, activation='sigmoid', input_dim=784),\n",
        "                    Dense(5, activation='sigmoid'),\n",
        "                    Dense(5, activation='sigmoid'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "adam_high = model.fit(X,y, epochs=30, validation_split=.2, shuffle=True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.2309 - accuracy: 0.1314 - val_loss: 2.1777 - val_accuracy: 0.1636\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.1375 - accuracy: 0.1711 - val_loss: 2.0678 - val_accuracy: 0.1720\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0850 - accuracy: 0.1834 - val_loss: 2.1367 - val_accuracy: 0.1822\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0972 - accuracy: 0.1847 - val_loss: 2.0844 - val_accuracy: 0.1787\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0455 - accuracy: 0.1840 - val_loss: 2.0545 - val_accuracy: 0.1830\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0391 - accuracy: 0.1838 - val_loss: 2.0343 - val_accuracy: 0.1792\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0417 - accuracy: 0.1834 - val_loss: 2.0412 - val_accuracy: 0.1822\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0395 - accuracy: 0.1839 - val_loss: 2.0468 - val_accuracy: 0.1899\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0377 - accuracy: 0.1808 - val_loss: 2.0275 - val_accuracy: 0.1726\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0240 - accuracy: 0.1763 - val_loss: 2.0220 - val_accuracy: 0.1763\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0164 - accuracy: 0.1863 - val_loss: 2.0342 - val_accuracy: 0.1777\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0228 - accuracy: 0.1814 - val_loss: 2.0748 - val_accuracy: 0.1829\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0690 - accuracy: 0.1855 - val_loss: 2.0615 - val_accuracy: 0.1828\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0346 - accuracy: 0.1853 - val_loss: 2.0181 - val_accuracy: 0.1801\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0097 - accuracy: 0.1844 - val_loss: 2.0119 - val_accuracy: 0.1849\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0067 - accuracy: 0.1841 - val_loss: 2.0076 - val_accuracy: 0.1900\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0052 - accuracy: 0.1847 - val_loss: 2.0083 - val_accuracy: 0.1842\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0049 - accuracy: 0.1857 - val_loss: 2.0099 - val_accuracy: 0.1845\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0045 - accuracy: 0.1866 - val_loss: 2.0099 - val_accuracy: 0.1880\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0047 - accuracy: 0.1864 - val_loss: 2.0047 - val_accuracy: 0.1819\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0029 - accuracy: 0.1854 - val_loss: 2.0143 - val_accuracy: 0.1861\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0248 - accuracy: 0.1763 - val_loss: 2.0361 - val_accuracy: 0.1708\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0296 - accuracy: 0.1753 - val_loss: 2.0277 - val_accuracy: 0.1786\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0647 - accuracy: 0.1705 - val_loss: 2.1191 - val_accuracy: 0.1614\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0718 - accuracy: 0.1706 - val_loss: 2.0641 - val_accuracy: 0.1760\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0623 - accuracy: 0.1689 - val_loss: 2.0566 - val_accuracy: 0.1717\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0346 - accuracy: 0.1746 - val_loss: 2.0172 - val_accuracy: 0.1822\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.0142 - accuracy: 0.1850 - val_loss: 2.0368 - val_accuracy: 0.1815\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 2.0620 - accuracy: 0.1872 - val_loss: 2.0790 - val_accuracy: 0.1870\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 8s 3ms/step - loss: 2.1016 - accuracy: 0.1834 - val_loss: 2.1053 - val_accuracy: 0.1867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUr1Y2DN1VJ-",
        "colab_type": "text"
      },
      "source": [
        "## Save Your Best Performing Model\n",
        "\n",
        "Practice saving the weights and architecture information of your best performing model. Reference the TensorFlow API documentation [here](https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjyJaJ9w1Tu6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a79a6191-7c49-475b-88ca-da16e3c651d3"
      },
      "source": [
        "##\n",
        "model.summary()\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 5)                 3925      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                60        \n",
            "=================================================================\n",
            "Total params: 4,045\n",
            "Trainable params: 4,045\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN-q5TO0Fw9R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a27e8f33-593d-4396-a823-5d6cf1bf3dc5"
      },
      "source": [
        "!mkdir -p saved_model\n",
        "model.save('saved_model/adam_low_model')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/adam_low_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV1pScqDF6vP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format\n",
        "\n",
        "new_model = tf.keras.models.load_model('saved_model/adam_low_model')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyuGY3RvGEFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e2914d39-61cf-4b45-ad80-47a2fbec005e"
      },
      "source": [
        "# Save the weights\n",
        "model.save_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# Create a new model instance\n",
        "#model = create_model()\n",
        "\n",
        "# Restore the weights\n",
        "model.load_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# Evaluate the model\n",
        "loss,acc = model.evaluate(X,  y, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3125/3125 - 6s - loss: 1.0343 - accuracy: 0.6703\n",
            "Restored model, accuracy: 67.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-98UwN0N82z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5271cb68-63cc-4c94-ac42-6f022d9c45ab"
      },
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '{checkpoint_dir}': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJrbh3qryi4w",
        "colab_type": "text"
      },
      "source": [
        "### Additional Written Tasks:\n",
        "In this section, you will need to search for resources: \n",
        "1. Investigate the various [loss functions](https://www.tensorflow.org/api_docs/python/tf/keras/losses). Which is best suited for the task at hand (predicting 1 / 0) and why? \n",
        "\n",
        "sparce categorical cross entropy seems like the best, we want something categorical. Entropy as I best understand it is the potential for change, so it's cross referencing that.\n",
        "\n",
        "2. What is the difference between a loss function and a metric? Why might we need both in Keras? \n",
        "\n",
        "\"The loss function is used to optimize your model. This is the function that will get minimized by the optimizer. A metric is used to judge the performance of your model.\"\n",
        "\n",
        "\n",
        "3. Investigate the various [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). Stochastic Gradient Descent (`sgd`) is not the learning algorithm dejour anyone. Why is that? What do newer optimizers such as `adam` have to offer? \n",
        "\n",
        "\"Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments. According to the paper Adam: A Method for Stochastic Optimization. Kingma et al., 2014, the method is \"computationally efficient, has little memory requirement, invariant to diagonal rescaling of gradients, and is well suited for problems that are large in terms of data/parameters\".\n",
        "\n",
        "\"Adamax - It is a variant of Adam based on the infinity norm. Default parameters follow those provided in the paper. Adamax is sometimes superior to adam, specially in models with embeddings.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzs4fd-RynDd",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals: \n",
        "\n",
        "- Research convolutional neural networks and try including convolution layers in your network.\n",
        "- Pick two classes and make QuickDraw a binary classification problem, how does your model architecture change?\n",
        "- Implement Cross Validation model evaluation on your Quickdraw implementation \n",
        "\n",
        "Watch some more videos on Gradient Descent:\n",
        "- [Gradient Descent, Step-by-Step](https://www.youtube.com/watch?v=sDv4f4s2SB8)  by StatQuest w/ Josh Starmer. This will help you understand the gradient descent based optimization that happens underneath the hood of neural networks. It uses a non-neural network example, which I believe is a gentler introduction. You will hear me refer to this technique as \"vanilla\" gradient descent. \n",
        "- [Stochastic Gradient Descent, Clearly Explained!!!](https://www.youtube.com/watch?v=vMh0zPT0tLI) by StatQuest w/ Josh Starmer. This builds on the techniques in the previous video.  This technique is the one that is actually implemented inside modern 'nets. \n",
        "- [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g649u1eo1R9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}